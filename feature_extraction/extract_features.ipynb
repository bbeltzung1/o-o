{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7187303d-d4a4-4673-a2d4-8f2ca4134120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.decomposition import PCA, SparsePCA, TruncatedSVD, IncrementalPCA\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "import scipy\n",
    "from itertools import chain\n",
    "import statistics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import concat\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.layers import Rescaling, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.image import rgb_to_grayscale, grayscale_to_rgb\n",
    "from tensorflow import tile\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "image_size = 224\n",
    "input_shape = (image_size, image_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9582cf04-5b5b-4211-9453-f4a982b0c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1300/1300 [01:46<00:00, 12.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data import\n",
    "\n",
    "drawings_names = os.listdir('img/')\n",
    "seasons = ['Autumn','Winter','Spring','Summer']\n",
    "i = 0\n",
    "drawings = []\n",
    "labels = list()\n",
    "\n",
    "for img in tqdm(drawings_names):\n",
    "    if not img.startswith('.'):\n",
    "        for season in seasons:\n",
    "            if season in img:\n",
    "                labels.append(str(season))\n",
    "        img = load_img('img/'+img, target_size=(224,224,3))\n",
    "        img = img_to_array(img)\n",
    "        img = expand_dims(img,axis=0)\n",
    "        img = preprocess_input(img)\n",
    "        img = np.array(img)\n",
    "        drawings.append(img)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3085b194-3fb8-49cc-922c-2a4ae53361e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import VGG19 to extract the activations at conv layers\n",
    "vgg = tensorflow.keras.applications.VGG19(weights='imagenet', include_top=True, input_shape = (224,224,3))\n",
    "ixs = []\n",
    "\n",
    "i=0\n",
    "for layer in vgg.layers:\n",
    "    if \"conv\" in layer.name:\n",
    "        ixs.append(i)\n",
    "    i=i+1\n",
    "\n",
    "outputs = [vgg.layers[i].output for i in ixs]\n",
    "feature_extraction_model = Model(inputs=vgg.input, outputs=outputs)\n",
    "\n",
    "kernels_size = []\n",
    "for i in range(len(feature_extraction_model.outputs)):\n",
    "    kernels_size.append((feature_extraction_model.outputs[i].shape[1],feature_extraction_model.outputs[i].shape[2]))\n",
    "\n",
    "# nombre de channels par couche\n",
    "nb_channels = []\n",
    "for i in range(len(feature_extraction_model.outputs)):\n",
    "    nb_channels.append(feature_extraction_model.outputs[i].shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb01bab-fd99-4179-8e42-84161445941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice 0 : La longueur d'un vecteur de la couche 1 pour une image donnée est de : 3211264 (taille kernel : 224x224 et nombre channels : 64)\n",
      "Indice 1 : La longueur d'un vecteur de la couche 2 pour une image donnée est de : 3211264 (taille kernel : 224x224 et nombre channels : 64)\n",
      "Indice 2 : La longueur d'un vecteur de la couche 4 pour une image donnée est de : 1605632 (taille kernel : 112x112 et nombre channels : 128)\n",
      "Indice 3 : La longueur d'un vecteur de la couche 5 pour une image donnée est de : 1605632 (taille kernel : 112x112 et nombre channels : 128)\n",
      "Indice 4 : La longueur d'un vecteur de la couche 7 pour une image donnée est de : 802816 (taille kernel : 56x56 et nombre channels : 256)\n",
      "Indice 5 : La longueur d'un vecteur de la couche 8 pour une image donnée est de : 802816 (taille kernel : 56x56 et nombre channels : 256)\n",
      "Indice 6 : La longueur d'un vecteur de la couche 9 pour une image donnée est de : 802816 (taille kernel : 56x56 et nombre channels : 256)\n",
      "Indice 7 : La longueur d'un vecteur de la couche 10 pour une image donnée est de : 802816 (taille kernel : 56x56 et nombre channels : 256)\n",
      "Indice 8 : La longueur d'un vecteur de la couche 12 pour une image donnée est de : 401408 (taille kernel : 28x28 et nombre channels : 512)\n",
      "Indice 9 : La longueur d'un vecteur de la couche 13 pour une image donnée est de : 401408 (taille kernel : 28x28 et nombre channels : 512)\n",
      "Indice 10 : La longueur d'un vecteur de la couche 14 pour une image donnée est de : 401408 (taille kernel : 28x28 et nombre channels : 512)\n",
      "Indice 11 : La longueur d'un vecteur de la couche 15 pour une image donnée est de : 401408 (taille kernel : 28x28 et nombre channels : 512)\n",
      "Indice 12 : La longueur d'un vecteur de la couche 17 pour une image donnée est de : 100352 (taille kernel : 14x14 et nombre channels : 512)\n",
      "Indice 13 : La longueur d'un vecteur de la couche 18 pour une image donnée est de : 100352 (taille kernel : 14x14 et nombre channels : 512)\n",
      "Indice 14 : La longueur d'un vecteur de la couche 19 pour une image donnée est de : 100352 (taille kernel : 14x14 et nombre channels : 512)\n",
      "Indice 15 : La longueur d'un vecteur de la couche 20 pour une image donnée est de : 100352 (taille kernel : 14x14 et nombre channels : 512)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ixs)):\n",
    "    print('Indice ' + str(i) + ' : The length of a vector from layer ' + str(ixs[i]) + ' for a given image is : ' + str(kernels_size[i][0]**2 * nb_channels[i]) +\n",
    "          ' (kernel size : ' + str(kernels_size[i][0]) + 'x' + str(kernels_size[i][0]) + ' and number of channels : ' + str(nb_channels[i]) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5204a-076b-4bcf-8178-9af81c89dbf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run for every depth (except 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a581ce6-f675-40ec-973d-35b057fb421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 15 # matches with the index above\n",
    "outputs = vgg.layers[ixs[depth]].output\n",
    "feature_extraction_model = Model(inputs=vgg.input, outputs=outputs)\n",
    "nb_channel = feature_extraction_model.outputs[0].shape[3]\n",
    "kernel_size = feature_extraction_model.outputs[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38448709-cdf9-48ff-b1a7-d05b7cae03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_row = np.zeros((len(drawings),kernel_size**2 * nb_channel), dtype = 'float16')\n",
    "\n",
    "for i in tqdm(range(len(drawings))): # for each image, extract features\n",
    "    tmp_drawing = drawings[i]\n",
    "    tmp_feature = feature_extraction_model.predict(tmp_drawing)\n",
    "    flattened_features = []\n",
    "    for j in range(nb_channel): # flattening of each feature that becomes a line of the matrix (for this layer)\n",
    "        flattened_features.append(tmp_feature[0,:,:,j].flatten())\n",
    "    flattened_features = list(chain.from_iterable(flattened_features))\n",
    "    features_row[i,:] = flattened_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7983945-174e-405d-b6c2-0bc76f564a14",
   "metadata": {},
   "source": [
    "### Number of Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60655a0-f780-41b2-980f-fc1c4c5d9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(features_row.nbytes/(1e+9)) + ' Gb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd657c46-a176-49b8-8d74-edb72634fdcf",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a6dd7-88e6-4360-92e4-2e25cd1e522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_features_row = scaler.fit_transform(features_row)\n",
    "pca = PCA(n_components = 0.8)\n",
    "X_pca = pca.fit_transform(standardized_features_row)\n",
    "X_pca.shape\n",
    "\n",
    "np.savez_compressed('features/PCA_table/features_PCA_' + str(depth) + '.npz', X_pca, delimiters=',')\n",
    "# data = np.load to load\n",
    "# data['arr_0'] to have the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5b8b5-f570-4f4d-9b0f-15211840f32c",
   "metadata": {},
   "source": [
    "#### Plot explained variance + cumulative explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac521b-087d-4ca5-963a-81be870bcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig('features/plot_variance/cumulative_' + str(depth))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e674b2-05e1-4ad8-b36c-31ad19fb14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(range(0,len(exp_var_pca)), exp_var_pca, where='mid',label='Individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig('features/plot_variance/variance_' + str(depth))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61a68a-4643-4717-b845-6642fb12fa7b",
   "metadata": {},
   "source": [
    "### SVC on the PCA to have the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4803c7a-140e-4634-934f-4c75bec0f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "scores = cross_val_score(clf, X_pca, labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370b9b5-622a-4b9d-b926-5b797fc2c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993403d-fd59-4966-a3f1-455d0c46888a",
   "metadata": {},
   "source": [
    "#### Save scores for this layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037557ca-7dab-4147-b57a-91e37f7a0d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('features/scores/score_' + str(depth) + '.csv', scores, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7de42-85e4-4373-9854-5c9dc10d15fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code for layers 0 and 1 to sample 50% of the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb90d0d-bc45-4c21-ab47-45bc67b0b1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1299/1299 [18:28<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "depth = 1 # only for layer 0 and 1\n",
    "outputs = vgg.layers[ixs[depth]].output\n",
    "feature_extraction_model = Model(inputs=vgg.input, outputs=outputs)\n",
    "nb_channel = feature_extraction_model.outputs[0].shape[3]\n",
    "kernel_size = feature_extraction_model.outputs[0].shape[1]\n",
    "\n",
    "\n",
    "# for layer 0 and 1, sample 50% :\n",
    "sampled_values = random.sample(range(kernel_size**2 * nb_channel),kernel_size**2 * nb_channel//2)\n",
    "\n",
    "features_row = np.zeros((len(drawings), len(sampled_values)), dtype = 'float16')\n",
    "\n",
    "\n",
    "#features_row = np.zeros((len(drawings),kernel_size**2 * nb_channel), dtype = 'float16')\n",
    "\n",
    "for i in tqdm(range(len(drawings))):\n",
    "    tmp_drawing = drawings[i]\n",
    "    tmp_feature = feature_extraction_model.predict(tmp_drawing)\n",
    "    flattened_features = []\n",
    "    for j in range(nb_channel):\n",
    "        flattened_features.append(tmp_feature[0,:,:,j].flatten())\n",
    "    flattened_features = list(chain.from_iterable(flattened_features))\n",
    "    features_row[i,:] = flattened_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f88c5b-4f6a-448f-bcc1-292a5aa9d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all features for each images, for layer 0 and 1\n",
    "np.savez_compressed('features/PCA_table/features_full_' + str(depth) + '.npz', features_row, delimiters=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216aa99-36b2-4e02-bafe-f1b8aee0fa4c",
   "metadata": {},
   "source": [
    "### Is a sample of 50% of the points enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d483b6-e9e5-4192-ad21-fd87eb60c9b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'features/PCA_table/features_full_1.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features_row \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures/PCA_table/features_full_1.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m features_row \u001b[38;5;241m=\u001b[39m features_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/lib/npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 417\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    418\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features/PCA_table/features_full_1.npz'"
     ]
    }
   ],
   "source": [
    "features_row = np.load('features/PCA_table/features_full_1.npz')\n",
    "features_row = features_row['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24c5df-16f7-461c-b485-ddce9c6933d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample 50% of points 10 000 times, do a t-test to see if this mean = total mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ad004e-04e9-4969-8fc3-d83417765add",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenne = features_row.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1097d564-16a4-4edd-8bc4-514be4b71b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78a33237-8558-4f74-9374-6b016e3cd363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:21<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "moyenne_sample = []\n",
    "for i in tqdm(range(50)):\n",
    "    moyenne_tmp = []\n",
    "    sampled = random.sample(range(kernel_size**2 * nb_channel), kernel_size**2 * nb_channel//2)\n",
    "    features_array = [ np.array(features_row[:,s]) for s in sampled]\n",
    "    x = np.mean(features_array)\n",
    "    moyenne_sample.append(x)\n",
    "    #print(moyenne_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09820518-2fb9-46fe-a394-e4d108f54797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=0.5018856132284956, pvalue=0.6179957940162921)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_1samp(moyenne_sample,moyenne) # p = 1.0 for layer 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d2c5a-08f7-4317-9e38-a60fb8d521f4",
   "metadata": {},
   "source": [
    "### PCA on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bbbfa-5fb1-4594-9438-38ba42936e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_features_row = scaler.fit_transform(features_row)\n",
    "pca = PCA(n_components = 0.8)\n",
    "X_pca = pca.fit_transform(standardized_features_row)\n",
    "X_pca.shape\n",
    "\n",
    "np.savez_compressed('features/PCA_table/features_PCA_' + str(depth) + 'b' +  '.npz', X_pca, delimiters=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae77baf-bfc5-4ddf-9126-db3074311dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig('features/plot_variance/cumulative_' + str(depth) + 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afaec3-5f2b-4d51-9d7c-52dc12bb34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(range(0,len(exp_var_pca)), exp_var_pca, where='mid',label='Individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig('features/plot_variance/variance_' + str(depth) + 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e993da-2617-4b0a-8e43-57ecc1a3b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "scores = cross_val_score(clf, X_pca, labels, cv=10)\n",
    "\n",
    "np.savetxt('features/scores/score_' + str(depth) + 'b' + '.csv', scores, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50baef6-8581-485f-9fc6-be0fbb8716db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature activation of the 2 FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f617eb-64f8-4ee0-9dbd-da940447f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 24 # FC layers : depth 23 and 24\n",
    "outputs = vgg.layers[depth].output\n",
    "feature_extraction_model = Model(inputs=vgg.input, outputs=outputs)\n",
    "length_fc = feature_extraction_model.outputs[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76788c-8d23-4a3b-89d3-853f567b149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_row = np.zeros((len(drawings),length_fc), dtype = 'float32')\n",
    "\n",
    "for i in tqdm(range(len(drawings))):\n",
    "    tmp_drawing = drawings[i]\n",
    "    tmp_feature = feature_extraction_model.predict(tmp_drawing)\n",
    "    features_row[i,:] = tmp_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5149a-b644-4bad-9781-31679a10fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_features_row = scaler.fit_transform(features_row)\n",
    "pca = PCA(n_components = 0.8)\n",
    "X_pca = pca.fit_transform(standardized_features_row)\n",
    "X_pca.shape\n",
    "\n",
    "np.savez_compressed('features/PCA_table/features_PCA_' + vgg.layers[depth].name + '.npz', X_pca, delimiters=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ee3ef-f035-45d1-b863-2e83a54a328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig('features/plot_variance/cumulative_' + vgg.layers[depth].name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa578fda-96be-4698-a388-6121794fcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(range(0,len(exp_var_pca)), exp_var_pca, where='mid',label='Individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig('features/plot_variance/variance_' + vgg.layers[depth].name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05462b58-9f4b-4041-9071-5675a9cb475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "scores = cross_val_score(clf, X_pca, labels, cv=10)\n",
    "\n",
    "np.savetxt('features/scores/score_' + vgg.layers[depth].name + '.csv', scores, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
